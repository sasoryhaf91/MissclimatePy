{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"MissClimatePy","text":"<p>MissClimatePy is a lightweight Python package for imputing and evaluating daily climate station records using only:</p> <ul> <li>Spatial coordinates: latitude, longitude, altitude </li> <li>Temporal information: year, month, day-of-year (optionally sine/cosine of day-of-year)</li> </ul> <p>It enforces a simple XYZT representation:</p> <p>X\u2013Y: latitude\u2013longitude\u2003\u2003Z: elevation\u2003\u2003T: time (calendar features)</p> <p>and intentionally ignores external covariates (reanalyses, satellite products, etc.). This makes workflows reproducible, transparent, and easy to port to other station networks and variables.</p> <p>MissClimatePy is designed for:</p> <ul> <li>Reconstructing complete daily series (e.g. 1991\u20132020) at station level  </li> <li>Studying Minimum Data Requirement (MDR) scenarios  </li> <li>Evaluating how far a station network can be interpolated using only its own geometry and calendar structure</li> </ul>"},{"location":"#key-features","title":"Key features","text":"<ul> <li>Global XYZT imputer </li> <li><code>MissClimateImputer</code> fits a single <code>RandomForestRegressor</code> on all observed rows.  </li> <li>Uses only <code>[lat, lon, alt, year, month, doy]</code> (plus optional cyclic <code>sin/cos(doy)</code>).</li> <li> <p>Produces a filled data frame and basic diagnostics (MAE, RMSE, R\u00b2) on observed rows.</p> </li> <li> <p>Station-wise evaluation </p> </li> <li><code>evaluate_stations</code> trains one model per station using K-nearest spatial neighbours (Haversine distance) or all other stations.  </li> <li>Optional controlled leakage via <code>include_target_pct</code> for MDR experiments.  </li> <li> <p>Returns a station report (daily, monthly, yearly metrics; train/test sizes; neighbours) and a prediction table.</p> </li> <li> <p>Local daily series reconstruction </p> </li> <li><code>impute_dataset</code> builds a full daily grid for each selected station and window.  </li> <li>Preserves original observations and fills gaps with model predictions.  </li> <li> <p>Output schema: <code>text     [station, date, latitude, longitude, altitude, &lt;target&gt;, source]</code>     where <code>source</code> is <code>\"observed\"</code> or <code>\"imputed\"</code>.</p> </li> <li> <p>Missing-data diagnostics </p> </li> <li> <p>Coverage, gap profiles, missingness matrices, and deterministic masking scenarios (<code>masking</code> module).</p> </li> <li> <p>Spatial neighbours </p> </li> <li> <p>Haversine-based neighbour distances and reusable neighbour maps (<code>neighbors</code> module).</p> </li> <li> <p>Visualisation helpers </p> </li> <li>Missingness matrices, metric distributions, parity plots, time-series overlays, spatial maps, and imputed-series plots (<code>viz</code> module).</li> </ul> <p>MissClimatePy currently targets daily continuous variables such as precipitation (<code>prec</code>), minimum temperature (<code>tmin</code>), maximum temperature (<code>tmax</code>), and evaporation (<code>evap</code>), but any scalar daily variable can be used as the target.</p>"},{"location":"#installation","title":"Installation","text":"<p>From a clone of the repository:</p> <pre><code>git clone https://github.com/sasoryhaf91/MissclimatePy.git\ncd MissclimatePy\npip install .\n</code></pre> <p>For development (recommended if you want to run tests or edit the code/paper):</p> <pre><code>pip install -e \".[dev]\"\npytest\n</code></pre>"},{"location":"#minimal-example-local-daily-imputation","title":"Minimal example: local daily imputation","text":"<p>The snippet below shows how to reconstruct daily minimum temperature (<code>tmin</code>) for stations in the State of Mexico (IDs starting with <code>\"15\"</code>) using only coordinates and calendar features:</p> <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom missclimatepy.impute import impute_dataset as impute\nfrom missclimatepy.viz import plot_imputed_series as pis\n\nurl = \"https://zenodo.org/records/17636066/files/smn_mx_daily_1991_2020.csv\"\ndf = pd.read_csv(url, parse_dates=[\"date\"])\n\n# Impute tmin for stations whose ID starts with \"15\"\ntmin_imputed = impute(\n    df,\n    id_col=\"station\",\n    date_col=\"date\",\n    lat_col=\"latitude\",\n    lon_col=\"longitude\",\n    alt_col=\"altitude\",\n    target_col=\"tmin\",\n    start=\"1991-01-01\",\n    end=\"2020-12-31\",\n    prefix=[\"15\"],\n    model_kind=\"rf\",\n    model_params={\"n_estimators\": 15, \"random_state\": 42, \"n_jobs\": -1},\n)\n\n# Visualise one station (e.g. 15017)\nax = pis(\n    df=tmin_imputed,\n    station=15017,\n    id_col=\"station\",\n    date_col=\"date\",\n    target_col=\"tmin\",\n    source_col=\"source\",\n    title=\"Minimum temperature imputed \u2013 station 15017\",\n)\n\nplt.show()\n</code></pre> <p>The resulting data frame <code>tmin_imputed</code> contains, for each selected station and day:</p> <pre><code>[station, date, latitude, longitude, altitude, tmin, source]\n</code></pre> <p>where <code>source</code> indicates whether the value is observed or imputed.</p>"},{"location":"#documentation-roadmap","title":"Documentation roadmap","text":"<p>Use the navigation bar to explore:</p> <ul> <li>Quickstart \u2013 step-by-step examples for the main workflows.  </li> <li>Data model \u2013 required columns and recommended preprocessing.  </li> <li>Global imputer \u2013 details and examples for <code>MissClimateImputer</code>.  </li> <li>Station-wise evaluation \u2013 MDR and interpolation experiments with <code>evaluate_stations</code>.  </li> <li>Local imputation \u2013 full daily reconstruction with <code>impute_dataset</code>.  </li> <li>Missing-data diagnostics \u2013 coverage, gaps, and masking.  </li> <li>Neighbours &amp; visualisation \u2013 spatial KNN utilities and plotting helpers.  </li> <li>API reference \u2013 summary of the public functions and classes.</li> </ul> <p>If you use MissClimatePy in your research, please see the Citation section in the project README or <code>CITATION.cff</code>.</p>"},{"location":"api/","title":"API reference","text":"<p>MissClimatePy works on daily, long-format climate tables and exposes a small, explicit set of functions oriented to:</p> <ul> <li>Station-wise evaluation of XYZT models, and  </li> <li>Local imputation of a single target variable per call.</li> </ul> <p>Throughout the API you always pass column names explicitly, so the package does not enforce a fixed schema.</p>"},{"location":"api/#data-model","title":"Data model","text":"<p>All core functions assume a long-format <code>pandas.DataFrame</code> with at least:</p> <ul> <li><code>id_col</code> \u2013 station identifier (string or integer)</li> <li><code>date_col</code> \u2013 daily timestamp (datetime-like)</li> <li><code>lat_col</code> \u2013 station latitude in decimal degrees</li> <li><code>lon_col</code> \u2013 station longitude in decimal degrees</li> <li><code>alt_col</code> \u2013 station elevation (meters above sea level)</li> <li><code>target_col</code> \u2013 climate variable to model/impute (e.g. <code>prec</code>, <code>tmin</code>, <code>tmax</code>, <code>evap</code>)</li> </ul> <p>Minimal example:</p> <pre><code>import pandas as pd\n\ndf = pd.DataFrame(\n    {\n        \"station\":   [\"S001\"] * 3 + [\"S002\"] * 3,\n        \"date\":      pd.to_datetime([\"1991-01-01\", \"1991-01-02\", \"1991-01-03\"] * 2),\n        \"latitude\":  [19.5] * 6,\n        \"longitude\": [-99.1] * 6,\n        \"altitude\":  [2300.0] * 6,\n        \"tmin\":      [8.0, None, 7.5, 9.0, None, 8.2],\n    }\n)\n</code></pre>"},{"location":"api/#core-evaluation-evaluate_stations","title":"Core evaluation: <code>evaluate_stations</code>","text":"<pre><code>from missclimatepy import evaluate_stations\n</code></pre> <p><code>evaluate_stations</code> performs station-wise model evaluation using an XYZT feature set:</p> <ul> <li>X\u2013Y: latitude\u2013longitude  </li> <li>Z: elevation  </li> <li>T: year, month, day-of-year (and optional harmonic transforms of DOY)</li> </ul> <p>For each target station, it:</p> <ol> <li>Builds a training pool from:</li> <li>All other stations, or</li> <li>A KNN subset defined by Haversine distance (lat\u2013lon), or</li> <li>A custom <code>neighbor_map</code>.</li> <li>Applies an optional Minimum Data Requirement based on the number of    non-missing target values in the chosen window.</li> <li>Optionally includes a fraction of the station\u2019s own history    (<code>include_target_pct</code>) using a precipitation-friendly stratified sampler    (month \u00d7 dry/wet) when the target is rainfall.</li> <li>Fits the chosen model backend (default: Random Forest).</li> <li>Computes daily, monthly, and annual metrics on a held-out test set.</li> <li>Optionally computes a baseline (Mean Climatology Model) to compare    against the learned model.</li> </ol>"},{"location":"api/#signature-simplified","title":"Signature (simplified)","text":"<pre><code>report, preds = evaluate_stations(\n    data,\n    *,\n    # required schema\n    id_col,\n    date_col,\n    lat_col,\n    lon_col,\n    alt_col,\n    target_col,\n    # temporal window\n    start=None,\n    end=None,\n    # feature config\n    add_cyclic=False,\n    feature_cols=None,\n    # station selection\n    prefix=None,\n    station_ids=None,\n    regex=None,\n    custom_filter=None,\n    min_station_rows=None,\n    # neighborhoods\n    k_neighbors=20,\n    neighbor_map=None,\n    # leakage\n    include_target_pct=0.0,\n    include_target_seed=42,\n    # model backend\n    model_kind=\"rf\",\n    model_params=None,\n    # baseline + metrics\n    baseline_kind=\"mcm_doy\",\n    agg_for_metrics=\"sum\",\n    # UX / logging\n    show_progress=False,\n    log_csv=None,\n    flush_every=20,\n    # saving\n    save_report_path=None,\n    parquet_compression=\"snappy\",\n)\n</code></pre>"},{"location":"api/#important-parameters","title":"Important parameters","text":"<ul> <li>Station selection</li> <li><code>prefix</code>: list of string prefixes; keeps stations whose id starts with     any of them (e.g. <code>[\"15\"]</code> for State of Mexico in SMN codes).</li> <li><code>station_ids</code>: explicit list of station ids to evaluate.</li> <li><code>regex</code>: regular expression on station ids.</li> <li><code>custom_filter</code>: <code>callable(sid) \u2192 bool</code> to keep or discard ids.</li> <li> <p>All filters have OR semantics; if none are provided, all stations are     considered.</p> </li> <li> <p>Minimum Data Requirement</p> </li> <li> <p><code>min_station_rows</code>: minimum number of observed target values in the     <code>[start, end]</code> window. Stations below this threshold are skipped.</p> </li> <li> <p>Neighborhood</p> </li> <li><code>k_neighbors</code>: if provided and <code>neighbor_map</code> is <code>None</code>, a Haversine KNN     neighbor map is constructed internally from per-station median coordinates.</li> <li> <p><code>neighbor_map</code>: custom precomputed mapping     <code>{station_id: [neighbor_id_1, ...]}</code>. When given, it overrides     <code>k_neighbors</code>.</p> </li> <li> <p>Leakage / inclusion</p> </li> <li><code>include_target_pct</code>:<ul> <li><code>0.0</code> \u2192 strict LOSO-like evaluation: no target rows in training.</li> <li><code>&gt; 0</code> \u2192 include that percentage of the station\u2019s own valid rows in   training (using month \u00d7 dry/wet stratification for rainfall).</li> </ul> </li> <li> <p><code>include_target_seed</code>: random seed for the stratified sampler.</p> </li> <li> <p>Model backend</p> </li> <li><code>model_kind</code>: currently supports (exact set may expand):<ul> <li><code>\"rf\"</code> \u2013 Random Forest (default)</li> <li><code>\"etr\"</code> \u2013 Extra Trees</li> <li><code>\"gbr\"</code> \u2013 Gradient Boosting</li> <li><code>\"ridge\"</code> \u2013 Ridge regression</li> <li><code>\"svr\"</code> \u2013 Support-Vector Regression</li> <li><code>\"knn\"</code> \u2013 K-Nearest Neighbors</li> <li><code>\"mlp\"</code> \u2013 Multi-layer Perceptron</li> </ul> </li> <li> <p><code>model_params</code>: dict of keyword arguments forwarded to the corresponding     scikit-learn regressor (e.g. <code>{\"n_estimators\": 200, \"max_depth\": 30}</code>).</p> </li> <li> <p>Baseline</p> </li> <li><code>baseline_kind</code>:<ul> <li><code>\"mcm_doy\"</code> \u2013 Mean Climatology Model: for each station and day-of-year   (1\u2013366), take the mean of observed values across years; the test-day   prediction is the corresponding DOY mean.</li> <li><code>None</code> \u2013 skip baseline computation.</li> </ul> </li> <li> <p>Baseline metrics are reported alongside model metrics.</p> </li> <li> <p>Metrics aggregation</p> </li> <li><code>agg_for_metrics</code>: <code>\"sum\"</code>, <code>\"mean\"</code>, or <code>\"median\"</code>:<ul> <li><code>\"sum\"</code> is natural for precipitation (monthly / annual totals).</li> <li><code>\"mean\"</code> or <code>\"median\"</code> are typical for temperature.</li> </ul> </li> </ul>"},{"location":"api/#return-values","title":"Return values","text":"<ul> <li> <p><code>report</code>: <code>DataFrame</code> with one row per evaluated station, including:</p> </li> <li> <p>Station id and metadata:</p> <ul> <li><code>station</code></li> <li><code>latitude</code>, <code>longitude</code>, <code>altitude</code> (median coordinates in window)</li> <li><code>rows_train</code>, <code>rows_test</code>, <code>n_rows</code> (test rows used for metrics)</li> <li><code>seconds</code> (wall-clock time per station)</li> <li><code>used_k_neighbors</code>, <code>include_target_pct</code></li> </ul> </li> <li>Model metrics:<ul> <li><code>MAE_d</code>, <code>RMSE_d</code>, <code>R2_d</code> \u2013 daily metrics</li> <li><code>MAE_m</code>, <code>RMSE_m</code>, <code>R2_m</code> \u2013 monthly aggregated metrics</li> <li><code>MAE_y</code>, <code>RMSE_y</code>, <code>R2_y</code> \u2013 annual aggregated metrics</li> </ul> </li> <li> <p>Baseline metrics (when <code>baseline_kind</code> is not <code>None</code>):</p> <ul> <li><code>MAE_d_base</code>, <code>RMSE_d_base</code>, <code>R2_d_base</code></li> <li><code>MAE_m_base</code>, <code>RMSE_m_base</code>, <code>R2_m_base</code></li> <li><code>MAE_y_base</code>, <code>RMSE_y_base</code>, <code>R2_y_base</code></li> </ul> </li> <li> <p><code>preds</code>: per-row predictions for the test splits, including:</p> </li> <li> <p><code>station</code>, <code>date</code>, <code>latitude</code>, <code>longitude</code>, <code>altitude</code></p> </li> <li><code>y_obs</code> \u2013 observed values</li> <li><code>y_mod</code> \u2013 model predictions</li> <li><code>y_base</code> \u2013 baseline predictions (if applicable)</li> </ul>"},{"location":"api/#core-imputation-impute_dataset","title":"Core imputation: <code>impute_dataset</code>","text":"<pre><code>from missclimatepy import impute_dataset\n</code></pre> <p><code>impute_dataset</code> performs local imputation of a single target variable:</p> <ul> <li>One local model per station (same XYZT feature set as <code>evaluate_stations</code>).</li> <li>Neighbors defined either by KNN (Haversine) or an explicit <code>neighbor_map</code>.</li> <li>Uses an optional <code>include_target_pct</code> to bring a fraction of the station\u2019s   own history into training.</li> <li>Generates a complete daily grid <code>[start, end]</code> for each imputed station.</li> <li>Preserves original observations and fills gaps with model predictions.</li> <li>Marks each day as <code>\"observed\"</code> or <code>\"imputed\"</code> via a <code>source</code> column.</li> </ul>"},{"location":"api/#signature-simplified_1","title":"Signature (simplified)","text":"<pre><code>imputed = impute_dataset(\n    data,\n    *,\n    id_col,\n    date_col,\n    lat_col,\n    lon_col,\n    alt_col,\n    target_col,\n    start=None,\n    end=None,\n    add_cyclic=False,\n    feature_cols=None,\n    prefix=None,\n    station_ids=None,\n    regex=None,\n    custom_filter=None,\n    min_station_rows=None,\n    k_neighbors=20,\n    neighbor_map=None,\n    include_target_pct=0.0,\n    include_target_seed=42,\n    model_kind=\"rf\",\n    model_params=None,\n    show_progress=False,\n    save_table_path=None,\n    parquet_compression=\"snappy\",\n)\n</code></pre> <p>The station-selection, MDR, neighborhood, leakage, and model_kind/model_params arguments behave exactly as in <code>evaluate_stations</code>.</p>"},{"location":"api/#behavior","title":"Behavior","text":"<p>For each selected station <code>sid</code>:</p> <ol> <li>Selects the station\u2019s rows inside <code>[start, end]</code> and ensures a daily grid    of dates in that window (even if the original table has gaps or entire dates    missing).</li> <li>Computes XYZT features for all rows where they can be constructed.</li> <li>Builds a training pool from neighbors (or all other stations) plus an    optional fraction of the station\u2019s own observed history (<code>include_target_pct</code>).</li> <li>If no valid training pool exists (e.g. no neighbors and no leakage), the    station is skipped and does not appear in the output.</li> <li>Otherwise, fits the chosen model and predicts the target for all days    in the grid:</li> <li>Where the original target is not missing \u2192 the original value is kept.</li> <li>Where the original target is missing or absent \u2192 the model prediction is      used.</li> <li>Annotates each row with a <code>source</code> label:</li> <li><code>\"observed\"</code> \u2013 original non-missing observation.</li> <li><code>\"imputed\"</code> \u2013 filled by the model.</li> </ol>"},{"location":"api/#return-value","title":"Return value","text":"<p>A tidy <code>DataFrame</code> with only the stations that could be imputed, with columns:</p> <ul> <li><code>station</code></li> <li><code>date</code></li> <li><code>latitude</code></li> <li><code>longitude</code></li> <li><code>altitude</code></li> <li><code>&lt;target_col&gt;</code> \u2013 imputed series</li> <li><code>source</code> \u2013 <code>\"observed\"</code> or <code>\"imputed\"</code></li> </ul> <p>The rows are restricted to <code>[start, end]</code>. Stations that do not meet <code>min_station_rows</code> or lack a valid training pool are silently omitted.</p>"},{"location":"api/#simple-example","title":"Simple example","text":"<pre><code>import pandas as pd\nfrom missclimatepy import impute_dataset\n\nurl = \"https://zenodo.org/records/17636066/files/smn_mx_daily_1991_2020.csv\"\ndf = pd.read_csv(url, parse_dates=[\"date\"])\n\ntmin_imputed = impute_dataset(\n    df,\n    id_col=\"station\",\n    date_col=\"date\",\n    lat_col=\"latitude\",\n    lon_col=\"longitude\",\n    alt_col=\"altitude\",\n    target_col=\"tmin\",\n    start=\"1991-01-01\",\n    end=\"2020-12-31\",\n    prefix=[\"15\"],  # e.g. State of Mexico in SMN coding\n    k_neighbors=20,\n    include_target_pct=50.0,\n    min_station_rows=365,\n    model_kind=\"rf\",\n    model_params={\"n_estimators\": 200, \"random_state\": 42, \"n_jobs\": -1},\n    show_progress=True,\n)\n\nprint(tmin_imputed.head())\n</code></pre>"},{"location":"api/#feature-utilities-features","title":"Feature utilities: <code>features</code>","text":"<pre><code>from missclimatepy import features\n</code></pre> <p>Main user-facing helpers:</p>"},{"location":"api/#ensure_datetime_naive","title":"<code>ensure_datetime_naive</code>","text":"<pre><code>from missclimatepy.features import ensure_datetime_naive\n\ndf[\"date\"] = ensure_datetime_naive(df[\"date\"])\n</code></pre> <ul> <li>Parses a Series to <code>datetime64[ns]</code> and drops any timezone information.</li> </ul>"},{"location":"api/#add_calendar_features","title":"<code>add_calendar_features</code>","text":"<pre><code>from missclimatepy.features import add_calendar_features\n\ndf_with_time = add_calendar_features(\n    df,\n    date_col=\"date\",\n    add_cyclic=True,  # add sin/cos(doy)\n)\n</code></pre> <p>Adds:</p> <ul> <li><code>year</code> (int32)</li> <li><code>month</code> (int16)</li> <li><code>doy</code> \u2013 day-of-year (int16)</li> <li>If <code>add_cyclic=True</code>:</li> <li><code>doy_sin</code>, <code>doy_cos</code> \u2013 harmonic transforms of DOY (<code>2\u03c0 * doy / 365.25</code>)</li> </ul>"},{"location":"api/#assemble_feature_columns","title":"<code>assemble_feature_columns</code>","text":"<pre><code>from missclimatepy.features import assemble_feature_columns\n\nfeat_cols = assemble_feature_columns(\n    lat_col=\"latitude\",\n    lon_col=\"longitude\",\n    alt_col=\"altitude\",\n    add_cyclic=True,\n    extra=[\"custom_feature_1\"],\n)\n</code></pre> <p>Returns the list of feature column names used for XYZT modeling.</p>"},{"location":"api/#station-selection-helpers","title":"Station selection helpers","text":"<p>These are mostly used internally, but can be useful when building custom workflows:</p> <ul> <li> <p><code>select_station_ids(data, id_col, prefix=None, station_ids=None, regex=None, custom_filter=None)</code>   \u2192 returns a list of station ids selected by the same OR semantics used in   <code>evaluate_stations</code> / <code>impute_dataset</code>.</p> </li> <li> <p><code>filter_by_min_station_rows(data, id_col, target_col, min_station_rows)</code>   \u2192 returns the subset of station ids with at least <code>min_station_rows</code> non-missing   target values.</p> </li> </ul>"},{"location":"api/#metrics-metrics","title":"Metrics: <code>metrics</code>","text":"<pre><code>from missclimatepy import metrics\n</code></pre> <p>Core functions:</p>"},{"location":"api/#compute_all_metrics","title":"<code>compute_all_metrics</code>","text":"<pre><code>from missclimatepy.metrics import compute_all_metrics\n\nscores = compute_all_metrics(y_true, y_pred, include_kge=True)\n# -&gt; {\"MAE\": ..., \"RMSE\": ..., \"R2\": ..., \"KGE\": ...}\n</code></pre> <p>Implements:</p> <ul> <li>MAE \u2013 mean absolute error</li> <li>RMSE \u2013 root mean square error</li> <li>R\u00b2 \u2013 coefficient of determination</li> <li>KGE \u2013 Kling\u2013Gupta Efficiency (optional)</li> </ul> <p>All metrics are robust to empty or degenerate inputs; in such cases they return <code>np.nan</code>.</p>"},{"location":"api/#aggregate_and_compute","title":"<code>aggregate_and_compute</code>","text":"<pre><code>from missclimatepy.metrics import aggregate_and_compute\n\nmetrics_monthly, df_monthly = aggregate_and_compute(\n    df_pred,\n    date_col=\"date\",\n    y_col=\"y_obs\",\n    yhat_col=\"y_mod\",\n    freq=\"M\",\n    agg=\"sum\",\n    include_kge=True,\n)\n</code></pre> <ul> <li>Resamples the series to a given <code>freq</code> (<code>\"M\"</code>, <code>\"YS\"</code>, <code>\"Q\"</code>, etc.).</li> <li>Applies an aggregation (<code>\"sum\"</code>, <code>\"mean\"</code>, <code>\"median\"</code>).</li> <li>Computes metrics between the aggregated observed and predicted series.</li> </ul> <p><code>evaluate_stations</code> uses this helper internally for monthly and annual metrics.</p>"},{"location":"api/#missing-data-diagnostics-masking","title":"Missing-data diagnostics: <code>masking</code>","text":"<pre><code>from missclimatepy import masking\n</code></pre> <p>Main helpers:</p> <ul> <li> <p><code>percent_missing_between(df, id_col, date_col, target_col, start, end)</code>   \u2192 percentage of missing days per station in a given window.</p> </li> <li> <p><code>gap_profile_by_station(df, id_col, date_col, target_col)</code>   \u2192 number of gaps, mean and maximum gap length per station.</p> </li> <li> <p><code>missing_matrix(df, id_col, date_col, target_col, start=None, end=None)</code>   \u2192 station \u00d7 date matrix of 1 (observed) / 0 (missing).</p> </li> <li> <p><code>describe_missing(df, id_col, date_col, target_col, start=None, end=None)</code>   \u2192 combined summary of coverage and gap statistics per station.</p> </li> <li> <p><code>apply_random_mask_by_station(df, id_col, date_col, target_col, percent_to_mask, random_state=None)</code>   \u2192 deterministically mask a given fraction of existing values per station;     useful for controlled validation experiments.</p> </li> </ul> <p>These tools are typically used before evaluation/imputation to select stations and design synthetic missingness scenarios.</p>"},{"location":"api/#spatial-neighbors-neighbors","title":"Spatial neighbors: <code>neighbors</code>","text":"<pre><code>from missclimatepy import neighbors\n</code></pre> <p>Key functions:</p>"},{"location":"api/#neighbor_distances","title":"<code>neighbor_distances</code>","text":"<pre><code>ndist = neighbors.neighbor_distances(\n    meta,\n    id_col=\"station\",\n    lat_col=\"latitude\",\n    lon_col=\"longitude\",\n    altitude_col=\"altitude\",\n    k_neighbors=10,\n    max_radius_km=None,\n    max_abs_altitude_diff=None,\n    include_self=False,\n)\n</code></pre> <ul> <li><code>meta</code> should have one row per station.</li> <li>Returns a tidy table with columns like:</li> <li><code>station</code>, <code>neighbor</code></li> <li><code>distance_km</code></li> <li><code>altitude_diff</code></li> </ul>"},{"location":"api/#build_neighbor_map","title":"<code>build_neighbor_map</code>","text":"<pre><code>nmap = neighbors.build_neighbor_map(\n    meta,\n    id_col=\"station\",\n    lat_col=\"latitude\",\n    lon_col=\"longitude\",\n    altitude_col=\"altitude\",\n    k_neighbors=10,\n    max_radius_km=None,\n    max_abs_altitude_diff=None,\n    include_self=False,\n)\n</code></pre> <ul> <li>Returns a dict <code>{station_id: [neighbor_id_1, ...]}</code>.</li> <li>Compatible with the <code>neighbor_map</code> argument of both   <code>evaluate_stations</code> and <code>impute_dataset</code>.</li> </ul>"},{"location":"api/#visualisation-viz","title":"Visualisation: <code>viz</code>","text":"<pre><code>from missclimatepy import viz\n</code></pre> <p>Most functions return a <code>matplotlib.axes.Axes</code> instance so that you can further customise them.</p> <p>Common helpers:</p> <ul> <li><code>plot_missing_matrix(df, id_col, date_col, target_col, max_stations=40, ax=None)</code></li> <li><code>plot_metrics_distribution(report, metric_cols=(\"MAE_d\", \"RMSE_d\", \"R2_d\"), kind=\"hist\", ax=None)</code></li> <li><code>plot_parity_scatter(df_pred, y_true_col=\"y_obs\", y_pred_col=\"y_mod\", ax=None)</code></li> <li><code>plot_time_series_overlay(df_pred, station_id, id_col, date_col, y_true_col, y_pred_col, ax=None)</code></li> <li><code>plot_spatial_scatter(meta, metric_col, lat_col=\"latitude\", lon_col=\"longitude\", ax=None)</code></li> <li><code>plot_gap_histogram(gaps, gap_col=\"max_gap\", ax=None)</code></li> <li><code>plot_imputed_series(df, station, id_col, date_col, target_col, source_col, ax=None, title=None)</code></li> <li><code>plot_imputation_coverage(df, id_col, source_col=\"source\", ax=None)</code></li> </ul> <p>Example:</p> <pre><code>import matplotlib.pyplot as plt\nfrom missclimatepy.viz import plot_imputed_series\n\nax = plot_imputed_series(\n    df=tmin_imputed,\n    station=15017,\n    id_col=\"station\",\n    date_col=\"date\",\n    target_col=\"tmin\",\n    source_col=\"source\",\n    title=\"Minimum temperature imputed \u2013 station 15017\",\n)\nplt.show()\n</code></pre> <p>This reference is intentionally compact. For more narrative examples and recommended MDR workflows, see:</p> <ul> <li><code>README.md</code> (high-level overview + quickstart)</li> <li><code>docs/mdr_protocol.md</code> (Minimum Data Requirement experiments)</li> <li>The JOSS paper in <code>paper/paper.md</code> (motivation and design rationale)</li> </ul>"},{"location":"getting_started/","title":"Getting started with MissClimatePy","text":"<p>MissClimatePy is a lightweight Python package for evaluating and imputing daily climate station records using only:</p> <ul> <li>Spatial coordinates: latitude, longitude, altitude  </li> <li>Temporal features: year, month, day-of-year (and optional harmonic features)</li> </ul> <p>It is designed for long station archives (multi-decadal daily series) where you want to:</p> <ul> <li>Reconstruct complete daily series (e.g. 1991\u20132020) at station level.</li> <li>Avoid dependence on external covariates (reanalysis, satellite, gridded products).</li> <li>Work in a transparent, reproducible XYZT framework.</li> </ul> <p>This page shows how to install the package, prepare your data, and run the two main workflows:</p> <ul> <li>Station-wise evaluation: <code>evaluate_stations</code></li> <li>Local station imputation: <code>impute_dataset</code></li> </ul>"},{"location":"getting_started/#1-installation","title":"1. Installation","text":""},{"location":"getting_started/#11-from-source-recommended-for-now","title":"1.1 From source (recommended for now)","text":"<p>Clone the repository and install in editable mode:</p> <pre><code>git clone https://github.com/sasoryhaf91/MissClimatePy.git\ncd MissClimatePy\n\n# create and activate your virtual env as you prefer, then:\npip install -e \".[dev]\"\n</code></pre> <p>Check that the package imports correctly:</p> <pre><code>import missclimatepy as mcp\nprint(mcp.__version__)\n</code></pre> <p>As soon as the package is on PyPI, you will also be able to do:</p> <pre><code>pip install missclimatepy\n</code></pre>"},{"location":"getting_started/#2-data-model","title":"2. Data model","text":"<p>MissClimatePy works with daily, long-format tables. The minimal schema is:</p> Column Type Description <code>station</code> string or integer Station identifier <code>date</code> datetime64 (daily) Daily timestamp <code>latitude</code> float Latitude in decimal degrees <code>longitude</code> float Longitude in decimal degrees <code>altitude</code> float Elevation above sea level (meters) <code>&lt;target&gt;</code> float (with NaNs allowed) Climate variable to impute (e.g. <code>tmin</code>) <p>You can use any column names you like: you will pass them explicitly to the functions.</p> <p>Example toy dataset:</p> <pre><code>import pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame(\n    {\n        \"station\":  [\"S1\"] * 5 + [\"S2\"] * 5,\n        \"date\":     pd.date_range(\"2020-01-01\", periods=5, freq=\"D\").tolist() * 2,\n        \"latitude\": [19.5] * 5 + [19.7] * 5,\n        \"longitude\":[-99.1] * 5 + [-99.3] * 5,\n        \"altitude\": [2300.0] * 10,\n        \"tmin\":     [8.0, np.nan, 7.5, np.nan, 7.8,\n                     9.0, 8.7, np.nan, 8.9, np.nan],\n    }\n)\n</code></pre>"},{"location":"getting_started/#3-station-wise-evaluation-with-evaluate_stations","title":"3. Station-wise evaluation with <code>evaluate_stations</code>","text":"<p>Use <code>evaluate_stations</code> when you want to quantify model performance at each station:</p> <ul> <li>It trains one model per station.</li> <li>The training pool uses other stations (or only K nearest neighbours).</li> <li>You can choose:</li> <li>the time window (<code>start</code> / <code>end</code>),</li> <li>the Minimum Data Requirement (<code>min_station_rows</code>),</li> <li>the fraction of the target station\u2019s own history to include in training (<code>include_target_pct</code>),</li> <li>the regression backend (<code>model_kind</code>, <code>model_params</code>).</li> </ul>"},{"location":"getting_started/#31-minimal-example-synthetic-data","title":"3.1 Minimal example (synthetic data)","text":"<pre><code>import pandas as pd\nfrom missclimatepy.evaluate import evaluate_stations\n\n# Reuse the toy df from above\ndf[\"date\"] = pd.to_datetime(df[\"date\"])\n\nreport, preds = evaluate_stations(\n    data=df,\n    # schema\n    id_col=\"station\",\n    date_col=\"date\",\n    lat_col=\"latitude\",\n    lon_col=\"longitude\",\n    alt_col=\"altitude\",\n    target_col=\"tmin\",\n    # time window\n    start=\"2020-01-01\",\n    end=\"2020-01-05\",\n    # station selection (here: all)\n    prefix=None,\n    min_station_rows=3,     # at least 3 observed tmin per station\n    # neighbours and leakage\n    k_neighbors=1,          # 1 nearest neighbour (Haversine on lat/lon)\n    include_target_pct=0.0, # pure LOSO-like: no target rows in training\n    # model backend\n    model_kind=\"rf\",\n    model_params={\"n_estimators\": 50, \"random_state\": 42, \"n_jobs\": -1},\n    # metrics aggregation\n    agg_for_metrics=\"mean\",\n    # UX\n    show_progress=True,\n)\n\nprint(\"Station-level report:\")\nprint(report)\n\nprint(\"\nRow-level predictions:\")\nprint(preds.head())\n</code></pre> <p>What you get:</p> <ul> <li> <p><code>report</code>: one row per station, with metrics and metadata, e.g.</p> </li> <li> <p><code>MAE_d</code>, <code>RMSE_d</code>, <code>R2_d</code> (daily)</p> </li> <li><code>MAE_m</code>, <code>RMSE_m</code>, <code>R2_m</code> (monthly aggregates)</li> <li><code>MAE_y</code>, <code>RMSE_y</code>, <code>R2_y</code> (annual aggregates)</li> <li><code>used_k_neighbors</code>, <code>include_target_pct</code>, <code>rows_train</code>, <code>rows_test</code></li> <li> <p><code>latitude</code>, <code>longitude</code>, <code>altitude</code> (station medoids)</p> </li> <li> <p><code>preds</code>: one row per evaluated observation with columns like:</p> </li> <li> <p><code>station</code>, <code>date</code>, <code>latitude</code>, <code>longitude</code>, <code>altitude</code></p> </li> <li><code>y_obs</code>, <code>y_mod</code> (observed vs modelled target)</li> </ul> <p>This is the core tool for MDR experiments, leave-one-station-out tests, and neighbour-based interpolation studies.</p>"},{"location":"getting_started/#4-local-imputation-with-impute_dataset","title":"4. Local imputation with <code>impute_dataset</code>","text":"<p>Use <code>impute_dataset</code> when you want to build complete daily series for a subset of stations over a given period:</p> <ul> <li>It calibrates a local model per station, using neighbours (or all others) plus, optionally, a fraction of the station\u2019s own observed history.</li> <li>It builds a full daily date grid for each station in the requested window.</li> <li>It returns only the imputed view, with a consistent schema:</li> </ul> <p><code>text   [station, date, latitude, longitude, altitude, &lt;target&gt;, source]</code></p> <p>where <code>source</code> is <code>\"observed\"</code> or <code>\"imputed\"</code>.</p>"},{"location":"getting_started/#41-minimal-example","title":"4.1 Minimal example","text":"<pre><code>import pandas as pd\nfrom missclimatepy.impute import impute_dataset\n\ndf[\"date\"] = pd.to_datetime(df[\"date\"])\n\nfilled = impute_dataset(\n    data=df,\n    # schema\n    id_col=\"station\",\n    date_col=\"date\",\n    lat_col=\"latitude\",\n    lon_col=\"longitude\",\n    alt_col=\"altitude\",\n    target_col=\"tmin\",\n    # window for the series to reconstruct\n    start=\"2020-01-01\",\n    end=\"2020-01-05\",\n    # which stations to impute (here: all)\n    prefix=None,\n    min_station_rows=1,        # allow stations with at least 1 observed value\n    # neighbourhood\n    k_neighbors=1,\n    include_target_pct=50.0,   # include 50% of the station\u2019s own observed history\n    include_target_seed=42,\n    # model backend\n    model_kind=\"rf\",\n    model_params={\"n_estimators\": 50, \"random_state\": 42, \"n_jobs\": -1},\n    # UX\n    show_progress=True,\n)\n\nprint(filled)\n</code></pre> <p>Typical output (simplified):</p> <pre><code>  station       date  latitude  longitude  altitude  tmin   source\n0      S1 2020-01-01      19.5     -99.1    2300.0   8.0  observed\n1      S1 2020-01-02      19.5     -99.1    2300.0   7.9  imputed\n2      S1 2020-01-03      19.5     -99.1    2300.0   7.5  observed\n3      S1 2020-01-04      19.5     -99.1    2300.0   7.7  imputed\n4      S1 2020-01-05      19.5     -99.1    2300.0   7.8  imputed\n...\n</code></pre> <p>Key points:</p> <ul> <li>There is one row per day per station in the requested window.</li> <li>Observed values are preserved (<code>source=\"observed\"</code>).</li> <li>Previously missing or non-existing days are filled (<code>source=\"imputed\"</code>).</li> <li>Stations that cannot be trained (no neighbours, or too few observed values) are skipped and do not appear in the output.</li> </ul>"},{"location":"getting_started/#5-quick-visual-check-of-an-imputed-series","title":"5. Quick visual check of an imputed series","text":"<p>MissClimatePy includes a small <code>viz</code> module. One of the most useful plots is <code>plot_imputed_series</code>, which overlays observed and imputed values for a single station.</p> <pre><code>import matplotlib.pyplot as plt\nfrom missclimatepy.viz import plot_imputed_series\n\nax = plot_imputed_series(\n    df=filled,\n    station=\"S1\",\n    id_col=\"station\",\n    date_col=\"date\",\n    target_col=\"tmin\",\n    source_col=\"source\",\n    title=\"Minimum temperature \u2013 station S1\",\n)\n\nplt.show()\n</code></pre> <p>By default, the function:</p> <ul> <li>Plots observed points and imputed points with different markers/alpha.</li> <li>Adds a legend explaining the <code>source</code> categories.</li> <li>Uses your specified <code>title</code>.</li> </ul> <p>This is particularly helpful for sanity checks and for creating figures for reports or papers.</p>"},{"location":"getting_started/#6-next-steps","title":"6. Next steps","text":"<p>Once you are comfortable with these basics, you can explore:</p> <ul> <li><code>docs/mdr_protocol.md</code>   For step-by-step Minimum Data Requirement (MDR) experiments.</li> <li><code>docs/api.md</code>   For a compact overview of functions and arguments.</li> <li><code>masking</code> utilities   To describe and simulate missingness patterns before evaluation or imputation.</li> <li><code>neighbors</code> utilities   To inspect and customise spatial neighbourhoods.</li> </ul> <p>MissClimatePy is intentionally minimalist: everything is driven by explicit arguments and long-format tables, so it should be straightforward to integrate into larger workflows or reproduce full MDR and interpolation studies.</p>"},{"location":"mdr_protocol/","title":"Minimum Data Requirement (MDR) protocol with MissClimatePy","text":"<p>This document describes a practical protocol for Minimum Data Requirement (MDR) experiments using <code>MissClimatePy</code>. The goal is to quantify how much local station history is needed (in percentage of observed days) for the XYZT Random Forest models to deliver acceptable interpolation / reconstruction performance.</p> <p>The workflow is fully reproducible and based on:</p> <ul> <li>A long-format daily station dataset.</li> <li>The station-wise evaluator <code>evaluate_stations</code>.</li> <li>The missing-data tools in <code>masking</code>.</li> <li>The neighbor utilities in <code>neighbors</code>.</li> <li>Standard metrics (MAE, RMSE, R\u00b2, KGE) computed per station.</li> </ul> <p>The protocol is agnostic to the country or network; here we use \u201cprecipitation\u201d (<code>prec</code>) or \u201cminimum temperature\u201d (<code>tmin</code>) as examples, but any continuous daily variable is compatible.</p>"},{"location":"mdr_protocol/#1-data-assumptions","title":"1. Data assumptions","text":"<p>MissClimatePy expects a long-format daily table with at least:</p> <ul> <li><code>station</code> \u2013 station identifier (string or integer)</li> <li><code>date</code> \u2013 daily timestamp (datetime-like)</li> <li><code>latitude</code> \u2013 decimal degrees</li> <li><code>longitude</code> \u2013 decimal degrees</li> <li><code>altitude</code> \u2013 meters above sea level</li> <li><code>&lt;target&gt;</code> \u2013 variable to analyze (e.g. <code>prec</code>, <code>tmin</code>, <code>tmax</code>, <code>evap</code>)</li> </ul> <p>You are free to choose the column names; they are passed explicitly to the functions.</p> <pre><code>import pandas as pd\n\nurl = \"https://zenodo.org/records/17636066/files/smn_mx_daily_1991_2020.csv\"\ndf = pd.read_csv(url, parse_dates=[\"date\"])\n\ndf.head()\n</code></pre> <p>Typical MDR experiments will:</p> <ul> <li>Fix a time window, e.g. 1991-01-01 to 2020-12-31.</li> <li>Focus on a single target variable (e.g. <code>prec</code> or <code>tmin</code>).</li> <li>Optionally restrict to a region or subset of stations (e.g. by ID prefix).</li> </ul>"},{"location":"mdr_protocol/#2-step-1-describe-missingness-and-select-stations","title":"2. Step 1 \u2013 Describe missingness and select stations","text":"<p>Before running MDR experiments, we recommend:</p> <ol> <li>Describing coverage (percentage of missing values per station).</li> <li>Describing gap structure (number and length of consecutive gaps).</li> <li>Filtering stations to ensure a reasonable minimum number of observed days.</li> </ol> <p>All of this is handled by <code>missclimatepy.masking</code>.</p> <pre><code>from missclimatepy import masking\n\nSTART = \"1991-01-01\"\nEND   = \"2020-12-31\"\nTARGET = \"tmin\"   # or \"prec\", \"tmax\", \"evap\"\n\n# 2.1 Coverage: percentage of missing days per station\ncoverage = masking.percent_missing_between(\n    df,\n    id_col=\"station\",\n    date_col=\"date\",\n    target_col=TARGET,\n    start=START,\n    end=END,\n)\n\n# 2.2 Gap profile\ngaps = masking.gap_profile_by_station(\n    df,\n    id_col=\"station\",\n    date_col=\"date\",\n    target_col=TARGET,\n)\n\n# 2.3 Combined descriptive summary\nsummary = masking.describe_missing(\n    df,\n    id_col=\"station\",\n    date_col=\"date\",\n    target_col=TARGET,\n    start=START,\n    end=END,\n)\n\nsummary.head()\n</code></pre> <p>From this summary you can define station filters, e.g.:</p> <ul> <li>Minimum percentage of observed days (e.g. \u2265 60 % coverage).</li> <li>Maximum tolerated maximum gap length (e.g. \u2264 365 days).</li> <li>Region filters (e.g. station IDs starting with <code>\"15\"</code> for State of Mexico).</li> </ul> <p>Example: stations with at least 25 full years of observations in 30 years:</p> <pre><code>import numpy as np\n\nmin_obs_days = 25 * 365  # ~25 years\nsummary[\"n_obs_days\"] = (1.0 - summary[\"pct_missing\"] / 100.0) * summary[\"n_days\"]\ngood_stations = summary.loc[summary[\"n_obs_days\"] &gt;= min_obs_days, \"station\"].tolist()\n\nlen(good_stations)\n</code></pre> <p>This station list can be passed to the evaluator as <code>station_ids=good_stations</code>.</p>"},{"location":"mdr_protocol/#3-step-2-build-spatial-neighbors-optional-but-recommended","title":"3. Step 2 \u2013 Build spatial neighbors (optional but recommended)","text":"<p>MDR experiments benefit from a controlled definition of spatial neighbors. MissClimatePy uses haversine distance on latitude/longitude and optionally stores altitude differences for diagnostics.</p> <pre><code>from missclimatepy import neighbors\n\n# One row per station with coordinates\nmeta = (\n    df[[\"station\", \"latitude\", \"longitude\", \"altitude\"]]\n    .drop_duplicates(\"station\")\n    .reset_index(drop=True)\n)\n\n# Tidy table of k nearest neighbors\nndist = neighbors.neighbor_distances(\n    meta,\n    id_col=\"station\",\n    lat_col=\"latitude\",\n    lon_col=\"longitude\",\n    altitude_col=\"altitude\",\n    k_neighbors=20,\n    max_radius_km=None,             # or e.g. 150.0\n    max_abs_altitude_diff=None,     # or e.g. 800.0\n    include_self=False,\n)\n\n# Mapping: station -&gt; list of neighbor IDs\nneighbor_map = neighbors.build_neighbor_map(\n    meta,\n    id_col=\"station\",\n    lat_col=\"latitude\",\n    lon_col=\"longitude\",\n    altitude_col=\"altitude\",\n    k_neighbors=20,\n)\n\nlen(neighbor_map)\n</code></pre> <p>You can either:</p> <ul> <li>Pass <code>k_neighbors=20</code> directly to <code>evaluate_stations</code> (let it build the map).</li> <li>Or pass <code>neighbor_map=neighbor_map</code> for explicit control and reproducibility.</li> </ul>"},{"location":"mdr_protocol/#4-step-3-station-wise-mdr-experiments-with-evaluate_stations","title":"4. Step 3 \u2013 Station-wise MDR experiments with <code>evaluate_stations</code>","text":"<p>The MDR protocol is based on varying the fraction of the target station\u2019s own history included in the training set, via <code>include_target_pct</code>.</p> <p>Intuition:</p> <ul> <li><code>include_target_pct = 0.0</code>: strict interpolation (LOSO-like). The station is never seen in training; only neighbors contribute.</li> <li>Higher values: local adaptation. A stratified fraction (month \u00d7 dry/wet for precipitation) of the station\u2019s observed history is allowed into training, simulating different Minimum Data Requirements.</li> </ul> <pre><code>from missclimatepy import evaluate_stations\n\nmdr_grid = [0.0, 4.0, 8.0, 16.0, 20.0, 40.0, 60.0, 80.0]\n\nall_reports = []\n\nfor pct in mdr_grid:\n    report, preds = evaluate_stations(\n        data=df,\n        id_col=\"station\",\n        date_col=\"date\",\n        lat_col=\"latitude\",\n        lon_col=\"longitude\",\n        alt_col=\"altitude\",\n        target_col=TARGET,\n        start=START,\n        end=END,\n        # station selection\n        station_ids=good_stations,      # from Step 1\n        # neighborhood (either k_neighbors or neighbor_map)\n        k_neighbors=20,\n        neighbor_map=None,\n        # MDR control: fraction of target history used in training\n        include_target_pct=pct,\n        include_target_seed=42,\n        # model configuration\n        model_kind=\"rf\",\n        model_params={\n            \"n_estimators\": 200,\n            \"max_depth\": 30,\n            \"n_jobs\": -1,\n            \"random_state\": 42,\n        },\n        # aggregation for monthly / annual metrics\n        agg_for_metrics=\"sum\" if TARGET == \"prec\" else \"mean\",\n        # baseline (optional; if enabled in your version)\n        baseline_kind=\"mcm_doy\",   # mean climatology by day-of-year\n        # UX\n        show_progress=True,\n    )\n\n    report[\"include_target_pct\"] = pct\n    all_reports.append(report)\n\nmdr_report = pd.concat(all_reports, ignore_index=True)\nmdr_report.head()\n</code></pre> <p>Each row in <code>mdr_report</code> typically contains:</p> <ul> <li>Station metadata: <code>station</code>, <code>latitude</code>, <code>longitude</code>, <code>altitude</code>.</li> <li>Training / test sizes: <code>rows_train</code>, <code>rows_test</code>, <code>n_rows</code>.</li> <li>Performance metrics:</li> <li>Daily: <code>MAE_d</code>, <code>RMSE_d</code>, <code>R2_d</code>, <code>KGE_d</code> (if available).</li> <li>Monthly: <code>MAE_m</code>, <code>RMSE_m</code>, <code>R2_m</code>, <code>KGE_m</code>.</li> <li>Annual: <code>MAE_y</code>, <code>RMSE_y</code>, <code>R2_y</code>, <code>KGE_y</code>.</li> <li>Baseline metrics (suffix <code>_base</code>) if a baseline is enabled.</li> <li>Configuration: <code>include_target_pct</code>, <code>used_k_neighbors</code>, timing.</li> </ul>"},{"location":"mdr_protocol/#5-step-4-summarize-mdr-curves","title":"5. Step 4 \u2013 Summarize MDR curves","text":"<p>The core MDR question is:</p> <p>How does performance change as we increase the fraction of local station history in training?</p> <p>A standard approach is to:</p> <ol> <li>Aggregate metrics by <code>(include_target_pct, metric)</code> using medians.</li> <li>Optionally stratify by region, altitude band, climate regime, etc.</li> </ol> <pre><code>import numpy as np\n\nsummary_mdr = (\n    mdr_report\n    .groupby(\"include_target_pct\")\n    .agg(\n        MAE_d_median=(\"MAE_d\", \"median\"),\n        RMSE_d_median=(\"RMSE_d\", \"median\"),\n        R2_d_median=(\"R2_d\", \"median\"),\n        KGE_d_median=(\"KGE_d\", \"median\"),\n    )\n    .reset_index()\n)\n\nsummary_mdr\n</code></pre> <p>You can then plot MDR curves, e.g. RMSE vs <code>include_target_pct</code>, or compare the Random Forest against the baseline (e.g. <code>RMSE_d</code> vs <code>RMSE_d_base</code>).</p>"},{"location":"mdr_protocol/#6-step-5-visual-diagnostics","title":"6. Step 5 \u2013 Visual diagnostics","text":"<p><code>missclimatepy.viz</code> provides several ready-made plots to interpret MDR results and model behavior.</p>"},{"location":"mdr_protocol/#61-metric-distributions","title":"6.1 Metric distributions","text":"<pre><code>import matplotlib.pyplot as plt\nfrom missclimatepy import viz\n\n# Subset a single MDR level, e.g. 16 %\nrep_16 = mdr_report[mdr_report[\"include_target_pct\"] == 16.0]\n\nviz.plot_metrics_distribution(\n    rep_16,\n    metric_cols=(\"MAE_d\", \"RMSE_d\", \"R2_d\"),\n    kind=\"hist\",\n)\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"mdr_protocol/#62-spatial-patterns-of-performance","title":"6.2 Spatial patterns of performance","text":"<pre><code>viz.plot_spatial_scatter(\n    rep_16,\n    lat_col=\"latitude\",\n    lon_col=\"longitude\",\n    value_col=\"RMSE_d\",\n    title=\"Daily RMSE at include_target_pct=16%\",\n)\nplt.show()\n</code></pre>"},{"location":"mdr_protocol/#63-time-series-overlays-or-imputed-series","title":"6.3 Time-series overlays or imputed series","text":"<p>Using the <code>preds</code> table from a particular MDR level, you can inspect individual stations:</p> <pre><code>some_station = rep_16[\"station\"].iloc[0]\n\nviz.plot_time_series_overlay(\n    preds,\n    station_id=some_station,\n    id_col=\"station\",\n    date_col=\"date\",\n    y_true_col=\"y_obs\",\n    y_pred_col=\"y_mod\",\n    title=f\"Observed vs modeled \u2013 station {some_station}\",\n)\nplt.show()\n</code></pre> <p>For fully imputed datasets produced by <code>impute_dataset</code> (with a <code>source</code> flag):</p> <pre><code>from missclimatepy.viz import plot_imputed_series\n\nax = plot_imputed_series(\n    df=imputed_df,\n    station=some_station,\n    id_col=\"station\",\n    date_col=\"date\",\n    target_col=TARGET,\n    source_col=\"source\",\n    title=f\"{TARGET} \u2013 observed vs imputed \u2013 station {some_station}\",\n)\nplt.show()\n</code></pre>"},{"location":"mdr_protocol/#7-interpreting-mdr-results","title":"7. Interpreting MDR results","text":"<p>Typical MDR findings include:</p> <ul> <li>A baseline performance at <code>include_target_pct=0.0</code>, representing pure spatial interpolation (LOSO-like).</li> <li>A rapid improvement in MAE/RMSE and KGE as the first 5\u201320 % of station history is included.</li> <li>A plateau beyond a certain threshold (e.g. 40\u201360 %), where additional history yields diminishing returns.</li> <li>Differences in MDR curves between regions (e.g. humid vs semi-arid climates, lowland vs highland stations).</li> </ul> <p>These patterns can be:</p> <ul> <li>Reported as MDR thresholds, e.g. \u201ca minimum of 20 % observed days is needed for median KGE \u2265 0.7\u201d.</li> <li>Used to classify stations into categories (well-constrained vs under-observed).</li> <li>Incorporated into data-quality guidelines for operational networks and retrospective reconstructions.</li> </ul>"},{"location":"mdr_protocol/#8-reproducibility-notes","title":"8. Reproducibility notes","text":"<p>To ensure fully reproducible MDR experiments:</p> <ul> <li>Fix <code>include_target_seed</code> for stratified sampling of target rows.</li> <li>Fix the <code>random_state</code> in the model parameters (e.g. Random Forest).</li> <li>Version control:</li> <li>The dataset (e.g. Zenodo DOI).</li> <li>The exact MissClimatePy version (e.g. <code>v0.1.1</code>).</li> <li>The MDR grid, station filters, and neighbor configuration.</li> <li>Prefer using an explicit <code>neighbor_map</code> saved to disk for cross-runs consistency.</li> </ul> <p>This protocol aims to be a template: you can adapt it to different periods, variables, regions, or model backends, while keeping the core XYZT and MDR philosophy of <code>MissClimatePy</code>.</p>"}]}